<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tips on </title>
    <link>https://cczhong11.github.io/categories/tips/</link>
    <description>Recent content in Tips on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 27 Mar 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://cczhong11.github.io/categories/tips/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Spark for ETL</title>
      <link>https://cczhong11.github.io/posts/cc/spark-etl/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://cczhong11.github.io/posts/cc/spark-etl/</guid>
      <description>There is not much information about how could we perform complex operation on pySpark. I summary some tips from stackoverflow and my experience. Hope it will be helpful for you.
How to Read JSON to DataFrame There are serveral ways to read json in Spark. The most common way is to load json in a DataFrame. Why not rdd? Because json contains some hierachy information and it could not represent well in RDD.</description>
    </item>
    
  </channel>
</rss>