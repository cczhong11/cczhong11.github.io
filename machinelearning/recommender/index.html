<!DOCTYPE html>
<html lang="en" class="wf-firasans-n4-active wf-active">
	<head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge"> <!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">   <meta name="generator" content="Hugo 0.47" /> 
<title>Recommendation &middot; TC blog</title>
<meta content="Recommendation - TC blog"
    property="og:title">
<meta content=" - Basic idea for Recommendation"
    property="og:description"> <!-- CSS -->
<link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,300i,400,400i|Roboto+Mono:300,300i,400,400i" rel="stylesheet">
<link rel="stylesheet" href="http://www.tczhong.com/css/print.css" media="print">
<link rel="stylesheet" href="http://www.tczhong.com/css/poole.css">
<link rel="stylesheet" href="http://www.tczhong.com/css/hyde.css"> <!-- Font-Awesome -->
<script defer src="https://use.fontawesome.com/releases/v5.0.10/js/all.js" integrity="sha384-slN8GvtUJGnv6ca26v8EzVaR9DC58QEwsIk9q1QXdCU8Yu8ck/tL/5szYlBbqmS+"
    crossorigin="anonymous"></script> <!-- highlight.js-->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/vs.min.css"> <!-- Customised CSS -->
<link rel="stylesheet" href="http://www.tczhong.com/css/custom.css"> <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]--> <!-- Icons -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://www.tczhong.com/apple-touch-icon-144-precomposed.png">
<link rel="shortcut icon" href="http://www.tczhong.com/favicon.png"> 

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-120924697-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-120924697-1');
</script>


	</head>
    <body>
        <div class="sidebar">
	<div class="container text-center sidebar-sticky">
		<div class="sidebar-about text-center">
			<a href="http://www.tczhong.com/"><h1 class="brand">TC blog</h1>
			 <img src="https://avatars2.githubusercontent.com/u/7358252?s=460&amp;v=4" alt="Author Image" class="img-circle headshot center"> </a>
			<p class="lead">
				 I am who I am. Love Cloud and Data science 
			</p>
		</div>
		
<div>
	<ul class="sidebar-nav">
		
		
				<li>
					<a href="http://www.tczhong.com/posts/"> <span>Posts</span></a>
				</li>
				<li>
					<a href="http://www.tczhong.com/about/hello"> <span>About</span></a>
				</li>
				<li>
					<a href="http://www.tczhong.com/tianchen_zhong.pdf"> <span>My Resume</span></a>
				</li>
				<li>
					<a href="http://www.tczhong.com/posts/project/index.html"> <span>Project</span></a>
				</li>
		</li>
	</ul>
</div>

        <p>
		<section class="row text-center">
	
	
	
	&nbsp;<a href="https://github.com/cczhong11"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	&nbsp;<a href="https://linkedin.com/in/tianchen-zhong"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	&nbsp;<a href="https://stackoverflow.com/users/7112540"><i class="fab fa-stack-overflow fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	&nbsp;<a href="mailto:tczhong24@gmail.com"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

        </p>
		<p class="copyright">&copy; 2018 Tc Zhong.
        <a href="https://creativecommons.org/licenses/by/4.0">Some Rights Reserved</a>.<br/>Built with <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/htr3n/hyde-hyde">hyde-hyde</a>.
        </p>
	</div>
	<div>
	</div>
</div>

        <div class="content container">
            <div class="post">
  <h1>Recommendation</h1>
  
  <div class="col-sm-12 col-md-12">
    <span class="text-left post-date meta">
            
       <i class="fa fa-calendar" aria-hidden="true"></i> May 5, 2018 
      
      
        
        
            in
            
            
                <a class="meta" href="http://www.tczhong.com/categories/machine-learning">MACHINE LEARNING</a>
                
            
        
      
      
      
      </span>  
  </div>    
  
  

<h1 id="recommendation">Recommendation</h1>

<h2 id="collaborative-filtering">Collaborative filtering</h2>

<p>Solely upon the preferences that other users have indicated for these items.(rating for items): row -&gt; users  column-&gt; items</p>

<p>The task of collaborative filtering, then, is to “fill in” the remaining entries of this matrix given the observed matrix. This X matrix that we observed is sparse but the unknown entries do not correspond to actual zeros in the matrix, but are rather just truly unknown.</p>

<p><img src="pic/matriex.png" alt="" /></p>

<p>▪   User-user approaches: In this approach we estimate a user’s rating of an item by finding “similar” users and then looking at their predictions for this item.
▪   Item-item approaches: These methods take the converse approach, and estimate a user’s rating of a item by finding similar items and then looking at the user’s rating of these similar items.
▪   Matrix factorization: Finally, the last class of approaches works a little bit differently, by aiming to construct a low-rank matrix that approximates the observed entries of the rating matrix.</p>

<h2 id="user-user-approaches">user-user approaches</h2>

<p>To start, let&rsquo;s introduce a slightly more formal bit of notation to define our problem.  Let $\hat{X}<em>{ij}$ denote our prediction for the $i$th user and $j$th item (i.e., this will be one of the elements that is missing from the matrix $X$, which we want to predict).  A common form for the prediction make by the user-user approach would be
$$
\hat{X}</em>{ij} = \bar{x}<em>i + \frac{\sum</em>{k:X<em>{kj} \neq 0} w</em>{ik} (X_{kj} - \bar{x}<em>k)}{\sum</em>{k:X<em>{kj} \neq 0} \lvert w</em>{ik} \rvert}
$$
where $\bar{x}<em>i$ denotes the average of the observed ratings for user $i$, and $w</em>{ik}$ denotes a <em>similarity weight</em> between user $i$ and user $k$ (which we will define shortly).  The intuition behind this approach is the following: if we want to predict user $i$&rsquo;s rating for item $j$, we look across all users that <em>do</em> have ratings for item $j$, and we average these together, weighted by a similarity function between the two users (we divide by $\sum<em>{k:X</em>{kj} \neq 0} \lvert w_{ik} \rvert$ so that we are taking a weighted average, noting that we take the absolute value because similarity weights can sometimes be positive or negative depending how we define then).  Because user&rsquo;s also frequently have their own &ldquo;baseline&rdquo; rating (i.e., some users naturally assign lower ratings than others), it&rsquo;s slightly better to do this modeling in the &ldquo;difference space&rdquo;, the difference between a user&rsquo;s rating and their mean rating, and then add re-scale by adding a user&rsquo;s mean score.</p>

<p>Let&rsquo;s see how this works in code.</p>

<pre><code class="language-python">def predict_user_user(X, W, user_means, i, j):
    &quot;&quot;&quot; Return prediction of X_(ij). &quot;&quot;&quot;
    return user_means[i] + (np.sum((X[:,j] - user_means) * (X[:,j] != 0) * W[i,:]) / 
                            np.sum((X[:,j] != 0) * np.abs(W[i,:])))
</code></pre>

<p>Item-item same as user-user instead of doing on columns</p>

<p>Weight could calculated by Pearson correlation. Let’s take the standard example of Pearson correlation (one of the most common methods for defining these weights)</p>

<p>$$
W<em>{ik} = \frac{\sum</em>{j \in \mathcal{I}<em>{ij}} (X</em>{ij} - \bar{x}<em>i)(X</em>{kj} - \bar{x}<em>k)}
{\sqrt{\sum</em>{j \in \mathcal{I}<em>{ij}}(X</em>{ij} - \bar{x}<em>i)^2} \sqrt{\sum</em>{j \in \mathcal{I}<em>{ij}}(X</em>{kj} - \bar{x}_k)^2}}
$$</p>

<pre><code class="language-python">def pearson(X,user_means, i,j):
    I = (X[i,:]!=0) * (X[j,:]!=0)
    xi = X[i,I] - user_means[i]
    xj = X[j,I] - user_means[j]
    return (xi @ xj)/(np.sqrt((xi @ xi)*(xj @ xj))+1e-12)

</code></pre>

<h2 id="matrix-factorization">Matrix factorization</h2>

<p>Using this approach, we tried to find two vectors $X \approx \hat{X} = UV, \;\; U \in \mathbb{R}^{m \times k}, \; V \in \mathbb{R}^{k \times n}$</p>

<h3 id="hypothesis-function">hypothesis function</h3>

<p>$\hat{X}<em>{ij} \equiv h</em>\theta(i,j) = u_i^T v_j$</p>

<p>our parameters are just all the $u$ and $v$ vectors, $\theta = {u<em>{1:m}, v</em>{1:n}}$.  One way to interpret this is that you can think of $u_i$ and $v_j$ as being something that is <em>both</em> like a feature vector and a parameter vector.  For a given user $i$, our hypothesis function is a linear hypothesis with paramters $u_i$, and we make our predictions by taking the inner product with these parameters and the item &ldquo;features&rdquo; $v_j$.  Thus, the goal of matrix factorization is to simultaneously learn both the per-user coefficients and the per-item features.</p>

<h3 id="loss-function">loss function</h3>

<p>$\ell(h<em>\theta(i,j), X</em>{ij}) = (h<em>\theta(i,j) - X</em>{ij})^2$</p>

<h3 id="optimization-problem">optimization problem</h3>

<p>$minimize<em>{u</em>{1:m},v<em>{1:n}} \sum</em>{i,j \in S} (u_i^T v<em>j - X</em>{ij})^2.$</p>

<h3 id="alternative-least-square">alternative least square</h3>

<p>In this method, we will fix one vector and calculate another vector to make sure that one has the minimum error rate.</p>

<p>$$
u<em>i = \left ( \sum</em>{j : (i,j) \in S} v_j v<em>j^T \right )^{-1} \left (\sum</em>{j : (i,j) \in S} v_j X_ij \right ), \;\; \ i=1,\ldots,m
$$</p>

<p>$$
v<em>j = \left ( \sum</em>{i : (i,j) \in S} u_i u<em>i^T \right )^{-1} \left (\sum</em>{i : (i,j) \in S} u_i X_ij \right ), \;\; j=1,\ldots,n
$$</p>

<h3 id="relation-to-pca">relation to PCA</h3>

<p>As mentioned above, there is a close relationship between matrix factorization for collaborative filtering and PCA.  Both are finding low-rank approximation to some matrix $X$.  But the key difference is that while <strong>PCA tries to find an approximation that matches <em>all</em> the entries of $X$</strong> (that is, $S$ would consist of the set of all valid $i,j$ pairs), matrix factorization for collaborative filtering only considers the loss on the observed entries.  Although we won&rsquo;t get into the specifics here, it turns out that this difference means that PCA can be solved optimally an eigenvalue decomposition (or equivalently, a singular value decomposition), whereas matrix factorization cannot be solved in this analytical manner, and the alternating optimization scheme we mentioned above has the potential for local optima.</p>

<p>Because of this, <strong>it is somewhat common to initialize matrix factorization with $u$ and $v$ terms determined by PCA</strong> (probably subtracting the mean of the data first as in typical PCA, so we don&rsquo;t try too hard <em>too</em> hard to fit the zero entries).  Doing so is not required by any means, but it is a nice way of proving a non-random initial solution to the problem, so that we can begin the matrix factorization steps.</p>

</div>
            <div class="footer">
                <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>

<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>


        <h2>Comments</h2>
        <div id="disqus_thread"></div>
<script type="text/javascript">
      (function () {
            
            
            
            if (location.hostname === "localhost" || 
            	location.hostname === "127.0.0.1" || 
            	location.hostname === "") {
                return;
			}
            var dsq = document.createElement('script');
            dsq.type = 'text/javascript';
            dsq.async = true;
            var disqus_shortname = 'tczhong';
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(
                  dsq);
      })();
</script>

<noscript>
	Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    

            </div>
        </div>
        
                
    </body>
</html>
