<!DOCTYPE html>
<html lang="en">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.67.0" />

    
    
    

<title>Maximum likelihood estimation â€¢ TC blog</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Maximum likelihood estimation"/>
<meta name="twitter:description" content="Basic idea for Maximum likelihood estimation"/>

<meta property="og:title" content="Maximum likelihood estimation" />
<meta property="og:description" content="Basic idea for Maximum likelihood estimation" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://www.tczhong.com/posts/machinelearning/maximum-likelihood-estimation/" />
<meta property="article:published_time" content="2018-05-01T00:00:00+00:00" />
<meta property="article:modified_time" content="2018-05-01T00:00:00+00:00" /><meta property="og:site_name" content="TC blog" />


    


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/vs.min.css">








<link rel="stylesheet" href="http://www.tczhong.com/scss/hyde-hyde.3081c4981fb69a2783dd36ecfdd0e6ba7a158d4cbfdd290ebce8f78ba0469fc6.css" integrity="sha256-MIHEmB&#43;2mieD3Tbs/dDmunoVjUy/3SkOvOj3i6BGn8Y=">


<link rel="stylesheet" href="http://www.tczhong.com/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://www.tczhong.com/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="http://www.tczhong.com/favicon.png">
    
    

</head>


    <body class=" ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="http://www.tczhong.com/">TC blog</a>
      </span>
      
        
        
        
        <div class="author-image">
          <img src="https://avatars2.githubusercontent.com/u/7358252?s=460&amp;v=4" alt="Author Image" class="img--circle img--headshot element--center">
        </div>
        
      
      
      <p class="site__description">
         I am who I am. Love Cloud and Data science 
      </p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">TC blog</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="http://www.tczhong.com/posts/">
						<span>Posts</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="http://www.tczhong.com/about/hello">
						<span>About</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="http://www.tczhong.com/tianchen_zhong.pdf">
						<span>My Resume</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="http://www.tczhong.com/posts/project/index.html">
						<span>Project</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <section class="social">
	
	
	
	<a href="https://github.com/cczhong11" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	<a href="https://linkedin.com/in/tianchen-zhong" rel="me"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	<a href="https://stackoverflow.com/users/7112540" rel="me"><i class="fab fa-stack-overflow fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	<a href="mailto:tczhong24@gmail.com" rel="me"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

      </div>
    </div>
    


  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>Maximum likelihood estimation</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> May 5, 2018
    
    
    
      
      
          in
          
          
              <a class="badge badge-category" href="http://www.tczhong.com/categories/machine-learning">MACHINE LEARNING</a>
              
          
      
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 3 min read
</div>


  </header>
  
  
  <div class="post">
    <h1 id="maximum-likelihood-estimation">Maximum likelihood estimation</h1>
<p>In the beginning, we could get a sample set $x_1,x_2,&hellip;$, and we assume these points are independent with each other. Then we could get the possibility for us to get these points.
$p(x_1,x_2,x_3&hellip;,x_m;\theta) = \prod_{i=1}^m p(x_i;\theta)$</p>
<p>So, what&rsquo;s the most possible $\theta$ under this circumstance, it is when this possibility get its maximum value. Therefore, we want to maximize $\theta$, to calculate
$$maximize_\theta ; \prod_{i=1}^m p(x^{(i)};\theta)$$
If we take the log to $p(x)$, we could get the **log likelihood** of the data, which is also equivalent to that value.
$$maximize_\theta ; \frac{1}{m} \sum_{i=1}^m \log p(x^{(i)};\theta)$$</p>
<p>Therefore, when we need to calculate $\phi$ in Bernoulli distribution, we could use $p(X = x; \phi) = \phi^x (1-\phi)^{(1-x)}$ to capture $x=1$ and $x=0$ at the same time. Then we could rewrite it to $maximize_{\phi} \sum_{i=1}^m (x^{(i)}\log\phi + (1-x^{(i)}) \log (1-\phi))$</p>
<p>In order to maximize this equation, let&rsquo;s take the derivative and set it equal to 0. So, we could know why we could estimate $\phi$ just like this.
$$\begin{split}
\frac{d}{d \phi} \sum_{i=1}^m \left (x^{(i)}\log\phi + (1-x^{(i)}) \log (1-\phi) \right )
&amp; = \sum_{i=1}^m \frac{d}{d \phi} \left ( x^{(i)}\log\phi + (1-x^{(i)}) \log (1-\phi) \right )  \<br>
&amp; = \sum_{i=1}^m \left ( \frac{x^{(i)}}{\phi} - \frac{1-x^{(i)}}{1-\phi} \right )
\end{split}$$</p>
<p>$$\begin{split}
&amp; \sum_{i=1}^m \left ( \frac{x^{(i)}}{\phi} - \frac{1-x^{(i)}}{1-\phi} \right ) = 0 \<br>
\Longrightarrow ;; &amp; \frac{\sum_{i=1}^m x^{(i)}}{\phi} - \frac{\sum_{i=1}^m (1-x^{(i)})} {1-\phi} = 0 \<br>
\Longrightarrow ;; &amp; (1-\phi) \sum_{i=1}^m x^{(i)}  - \phi \sum_{i=1}^m (1-x^{(i)}) = 0 \<br>
\Longrightarrow ;; &amp; \sum_{i=1}^m x^{(i)} = \phi \sum_{i=1}^m (x^{(i)} + (1-x^{(i)})) \<br>
\Longrightarrow ;; &amp; \sum_{i=1}^m x^{(i)} = \phi m \<br>
\Longrightarrow ;; &amp; \phi = \frac{\sum_{i=1}^m x^{(i)}}{m}.
\end{split}$$</p>
<h2 id="naive-bayes">Naive bayes</h2>
<p>Naive bayes is an easy method, the key is to calculate $$p(Y \mid X) = \frac{p(X \mid Y)p(Y)}{\sum_y p(X \mid y) p(y)}$$. We could calculate $P(X \ mid Y)$ and $P(Y)$ respectively.</p>
<p>The naive Bayes approach, however, is to make the additional assumption that the individual features  $X_i$  are conditionally independent given  $Y$ . This lets us represent the condition $p(X \mid Y) = \prod_{i=1}^n p(X_i \mid Y)$.</p>
<p>For example, we need to detect spam mail. We need to training the classifier. The training data tells us $P(words|spam)$ and $P(words'|not spam)$, then we could get the $P(spam)$, we could use $P(spam|words&rsquo;') = \frac{p(words|spam)P(spam)}{p(words|spam)P(spam)+p(words|not spam)P(not spam)}$</p>
<p>We could use log to avoid too small value yield from $\prod$, like $\log p(y) + \sum_{i=1}^n \log p(x_i \mid y)$.</p>
<p>We also could use laplace smoothing to avoid zero. $\phi_i^y = \frac{\sum_{j=1}^m x_i^{(j)} \mathrm{1}{y^{(j)} = y} + 1}{\sum_{j=1}^m \mathrm{1}{y^{(j)} = y} + 2}$</p>
<h2 id="logistic-regression">logistic regression</h2>
<p>We could get this formula from logistic regression and we also could think it using MLE.</p>
<p>$minimize_\theta \sum_{i=1}^m \ell_{\mathrm{logistic}}(h_\theta(x^{(i)}),y^{(i)}) ; \equiv ; minimize_\theta ;; \sum_{i=1}^m \log(1+\exp(-h_\theta(x^{(i)})\cdot y^{(i)})$</p>

  </div>
  

<div class="navigation navigation-single">
    
    <a href="http://www.tczhong.com/posts/machinelearning/neuralnetwork/" class="navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">Neural network</span>
    </a>
    
    
    <a href="http://www.tczhong.com/posts/machinelearning/logistic-regression/" class="navigation-next">
      <span class="navigation-tittle">Logistic regression</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  

  
    
        <div id="disqus_thread"></div>
<script type="text/javascript">
    

    (function () {
    if (location.hostname === "localhost" ||
      location.hostname === "127.0.0.1" ||
      location.hostname === "") {
      return;
    }
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    var disqus_shortname = 'tczhong';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || 
      document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

<noscript>
  Please enable JavaScript to view the
  <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by
  <span class="logo-disqus">Disqus</span>
</a>

    


</article>


        </div>
        
    

<script defer src="https://use.fontawesome.com/releases/v5.11.2/js/all.js" integrity="sha384-b3ua1l97aVGAPEIe48b4TC60WUQbQaGi2jqAWM90y0OZXZeyaTCWtBTKtjW2GXG1" crossorigin="anonymous"></script>


    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
        
    <script type="text/javascript">
        
        hljs.initHighlightingOnLoad();
    </script>
    



    



    </body>
</html>
