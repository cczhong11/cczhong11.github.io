<!DOCTYPE html>
<html lang="en">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.67.0" />

    
    
    

<title>Recommendation • TC blog</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Recommendation"/>
<meta name="twitter:description" content="Basic idea for Recommendation"/>

<meta property="og:title" content="Recommendation" />
<meta property="og:description" content="Basic idea for Recommendation" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://www.tczhong.com/posts/machinelearning/recommender/" />
<meta property="article:published_time" content="2018-05-01T00:00:00+00:00" />
<meta property="article:modified_time" content="2018-05-01T00:00:00+00:00" /><meta property="og:site_name" content="TC blog" />


    


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/vs.min.css">








<link rel="stylesheet" href="http://www.tczhong.com/scss/hyde-hyde.3081c4981fb69a2783dd36ecfdd0e6ba7a158d4cbfdd290ebce8f78ba0469fc6.css" integrity="sha256-MIHEmB&#43;2mieD3Tbs/dDmunoVjUy/3SkOvOj3i6BGn8Y=">


<link rel="stylesheet" href="http://www.tczhong.com/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://www.tczhong.com/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="http://www.tczhong.com/favicon.png">
    
    

</head>


    <body class=" ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="http://www.tczhong.com/">TC blog</a>
      </span>
      
        
        
        
        <div class="author-image">
          <img src="https://avatars2.githubusercontent.com/u/7358252?s=460&amp;v=4" alt="Author Image" class="img--circle img--headshot element--center">
        </div>
        
      
      
      <p class="site__description">
         I am who I am. Love Cloud and Data science 
      </p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">TC blog</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="http://www.tczhong.com/posts/">
						<span>Posts</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="http://www.tczhong.com/about/hello">
						<span>About</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="http://www.tczhong.com/tianchen_zhong.pdf">
						<span>My Resume</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="http://www.tczhong.com/posts/project/index.html">
						<span>Project</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <section class="social">
	
	
	
	<a href="https://github.com/cczhong11" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	<a href="https://linkedin.com/in/tianchen-zhong" rel="me"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	<a href="https://stackoverflow.com/users/7112540" rel="me"><i class="fab fa-stack-overflow fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	<a href="mailto:tczhong24@gmail.com" rel="me"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

      </div>
    </div>
    


  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>Recommendation</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> May 5, 2018
    
    
    
      
      
          in
          
          
              <a class="badge badge-category" href="http://www.tczhong.com/categories/machine-learning">MACHINE LEARNING</a>
              
          
      
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 5 min read
</div>


  </header>
  
  
  <div class="post">
    <h1 id="recommendation">Recommendation</h1>
<h2 id="collaborative-filtering">Collaborative filtering</h2>
<p>Solely upon the preferences that other users have indicated for these items.(rating for items): row -&gt; users  column-&gt; items</p>
<p>The task of collaborative filtering, then, is to “fill in” the remaining entries of this matrix given the observed matrix. This X matrix that we observed is sparse but the unknown entries do not correspond to actual zeros in the matrix, but are rather just truly unknown.</p>
<p><img src="pic/matriex.png" alt=""></p>
<p>▪	User-user approaches: In this approach we estimate a user’s rating of an item by finding “similar” users and then looking at their predictions for this item.
▪	Item-item approaches: These methods take the converse approach, and estimate a user’s rating of a item by finding similar items and then looking at the user’s rating of these similar items.
▪	Matrix factorization: Finally, the last class of approaches works a little bit differently, by aiming to construct a low-rank matrix that approximates the observed entries of the rating matrix.</p>
<h2 id="user-user-approaches">user-user approaches</h2>
<p>To start, let&rsquo;s introduce a slightly more formal bit of notation to define our problem.  Let $\hat{X}<em>{ij}$ denote our prediction for the $i$th user and $j$th item (i.e., this will be one of the elements that is missing from the matrix $X$, which we want to predict).  A common form for the prediction make by the user-user approach would be
$$
\hat{X}</em>{ij} = \bar{x}<em>i + \frac{\sum</em>{k:X_{kj} \neq 0} w_{ik} (X_{kj} - \bar{x}_k)}{\sum_{k:X_{kj} \neq 0} \lvert w_{ik} \rvert}
$$
where $\bar{x}_i$ denotes the average of the observed ratings for user $i$, and $w_{ik}$ denotes a _similarity weight_ between user $i$ and user $k$ (which we will define shortly).  The intuition behind this approach is the following: if we want to predict user $i$'s rating for item $j$, we look across all users that _do_ have ratings for item $j$, and we average these together, weighted by a similarity function between the two users (we divide by $\sum_{k:X_{kj} \neq 0} \lvert w_{ik} \rvert$ so that we are taking a weighted average, noting that we take the absolute value because similarity weights can sometimes be positive or negative depending how we define then).  Because user&rsquo;s also frequently have their own &ldquo;baseline&rdquo; rating (i.e., some users naturally assign lower ratings than others), it&rsquo;s slightly better to do this modeling in the &ldquo;difference space&rdquo;, the difference between a user&rsquo;s rating and their mean rating, and then add re-scale by adding a user&rsquo;s mean score.</p>
<p>Let&rsquo;s see how this works in code.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">predict_user_user</span>(X, W, user_means, i, j):
    <span style="color:#e6db74">&#34;&#34;&#34; Return prediction of X_(ij). &#34;&#34;&#34;</span>
    <span style="color:#66d9ef">return</span> user_means[i] <span style="color:#f92672">+</span> (np<span style="color:#f92672">.</span>sum((X[:,j] <span style="color:#f92672">-</span> user_means) <span style="color:#f92672">*</span> (X[:,j] <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>) <span style="color:#f92672">*</span> W[i,:]) <span style="color:#f92672">/</span> 
                            np<span style="color:#f92672">.</span>sum((X[:,j] <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>abs(W[i,:])))
</code></pre></div><p>Item-item same as user-user instead of doing on columns</p>
<p>Weight could calculated by Pearson correlation. Let’s take the standard example of Pearson correlation (one of the most common methods for defining these weights)</p>
<p>$$
W_{ik} = \frac{\sum_{j \in \mathcal{I}_{ij}} (X_{ij} - \bar{x}_i)(X_{kj} - \bar{x}_k)}
{\sqrt{\sum_{j \in \mathcal{I}_{ij}}(X_{ij} - \bar{x}_i)^2} \sqrt{\sum_{j \in \mathcal{I}_{ij}}(X_{kj} - \bar{x}_k)^2}}
$$</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">pearson</span>(X,user_means, i,j):
    I <span style="color:#f92672">=</span> (X[i,:]<span style="color:#f92672">!=</span><span style="color:#ae81ff">0</span>) <span style="color:#f92672">*</span> (X[j,:]<span style="color:#f92672">!=</span><span style="color:#ae81ff">0</span>)
    xi <span style="color:#f92672">=</span> X[i,I] <span style="color:#f92672">-</span> user_means[i]
    xj <span style="color:#f92672">=</span> X[j,I] <span style="color:#f92672">-</span> user_means[j]
    <span style="color:#66d9ef">return</span> (xi <span style="color:#960050;background-color:#1e0010">@</span> xj)<span style="color:#f92672">/</span>(np<span style="color:#f92672">.</span>sqrt((xi <span style="color:#960050;background-color:#1e0010">@</span> xi)<span style="color:#f92672">*</span>(xj <span style="color:#960050;background-color:#1e0010">@</span> xj))<span style="color:#f92672">+</span><span style="color:#ae81ff">1e-12</span>)

</code></pre></div><h2 id="matrix-factorization">Matrix factorization</h2>
<p>Using this approach, we tried to find two vectors $X \approx \hat{X} = UV, ;; U \in \mathbb{R}^{m \times k}, ; V \in \mathbb{R}^{k \times n}$</p>
<h3 id="hypothesis-function">hypothesis function</h3>
<p>$\hat{X}<em>{ij} \equiv h</em>\theta(i,j) = u_i^T v_j$</p>
<p>our parameters are just all the $u$ and $v$ vectors, $\theta = {u_{1:m}, v_{1:n}}$.  One way to interpret this is that you can think of $u_i$ and $v_j$ as being something that is _both_ like a feature vector and a parameter vector.  For a given user $i$, our hypothesis function is a linear hypothesis with paramters $u_i$, and we make our predictions by taking the inner product with these parameters and the item &ldquo;features&rdquo; $v_j$.  Thus, the goal of matrix factorization is to simultaneously learn both the per-user coefficients and the per-item features.</p>
<h3 id="loss-function">loss function</h3>
<p>$\ell(h_\theta(i,j), X_{ij}) = (h_\theta(i,j) - X_{ij})^2$</p>
<h3 id="optimization-problem">optimization problem</h3>
<p>$minimize_{u_{1:m},v_{1:n}} \sum_{i,j \in S} (u_i^T v_j - X_{ij})^2.$</p>
<h3 id="alternative-least-square">alternative least square</h3>
<p>In this method, we will fix one vector and calculate another vector to make sure that one has the minimum error rate.</p>
<p>$$
u_i = \left ( \sum_{j : (i,j) \in S} v_j v_j^T \right )^{-1} \left (\sum_{j : (i,j) \in S} v_j X_ij \right ), ;; \ i=1,\ldots,m
$$</p>
<p>$$
v_j = \left ( \sum_{i : (i,j) \in S} u_i u_i^T \right )^{-1} \left (\sum_{i : (i,j) \in S} u_i X_ij \right ), ;; j=1,\ldots,n
$$</p>
<h3 id="relation-to-pca">relation to PCA</h3>
<p>As mentioned above, there is a close relationship between matrix factorization for collaborative filtering and PCA.  Both are finding low-rank approximation to some matrix $X$.  But the key difference is that while <strong>PCA tries to find an approximation that matches <em>all</em> the entries of $X$</strong> (that is, $S$ would consist of the set of all valid $i,j$ pairs), matrix factorization for collaborative filtering only considers the loss on the observed entries.  Although we won&rsquo;t get into the specifics here, it turns out that this difference means that PCA can be solved optimally an eigenvalue decomposition (or equivalently, a singular value decomposition), whereas matrix factorization cannot be solved in this analytical manner, and the alternating optimization scheme we mentioned above has the potential for local optima.</p>
<p>Because of this, <strong>it is somewhat common to initialize matrix factorization with $u$ and $v$ terms determined by PCA</strong> (probably subtracting the mean of the data first as in typical PCA, so we don&rsquo;t try too hard <em>too</em> hard to fit the zero entries).  Doing so is not required by any means, but it is a nice way of proving a non-random initial solution to the problem, so that we can begin the matrix factorization steps.</p>

  </div>
  

<div class="navigation navigation-single">
    
    <a href="http://www.tczhong.com/posts/cc/undertow/" class="navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">Undertow configuration</span>
    </a>
    
    
    <a href="http://www.tczhong.com/posts/machinelearning/probability_modeling/" class="navigation-next">
      <span class="navigation-tittle">Probability modeling</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  

  
    
        <div id="disqus_thread"></div>
<script type="text/javascript">
    

    (function () {
    if (location.hostname === "localhost" ||
      location.hostname === "127.0.0.1" ||
      location.hostname === "") {
      return;
    }
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    var disqus_shortname = 'tczhong';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || 
      document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

<noscript>
  Please enable JavaScript to view the
  <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by
  <span class="logo-disqus">Disqus</span>
</a>

    


</article>


        </div>
        
    

<script defer src="https://use.fontawesome.com/releases/v5.11.2/js/all.js" integrity="sha384-b3ua1l97aVGAPEIe48b4TC60WUQbQaGi2jqAWM90y0OZXZeyaTCWtBTKtjW2GXG1" crossorigin="anonymous"></script>


    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
        
    <script type="text/javascript">
        
        hljs.initHighlightingOnLoad();
    </script>
    



    



    </body>
</html>
