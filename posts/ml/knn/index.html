<!DOCTYPE html>
<html lang="en">
    
    


    <head>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta http-equiv="Cache-Control" content="public" />
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.115.2">

    
    
    

<title>K Nearest Neighbor, K-Means and EM algorithm â€¢ TC blog</title>


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="K Nearest Neighbor, K-Means and EM algorithm"/>
<meta name="twitter:description" content="An article about some basic concepts for KNN"/>

<meta property="og:title" content="K Nearest Neighbor, K-Means and EM algorithm" />
<meta property="og:description" content="An article about some basic concepts for KNN" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.tczhong.com/posts/ml/knn/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-12-01T00:00:00+00:00" />
<meta property="article:modified_time" content="2018-12-01T00:00:00+00:00" /><meta property="og:site_name" content="TC blog" />


    


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/vs.min.css">








<link rel="stylesheet" href="https://www.tczhong.com/scss/hyde-hyde.3081c4981fb69a2783dd36ecfdd0e6ba7a158d4cbfdd290ebce8f78ba0469fc6.css" integrity="sha256-MIHEmB&#43;2mieD3Tbs/dDmunoVjUy/3SkOvOj3i6BGn8Y=">


<link rel="stylesheet" href="https://www.tczhong.com/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://www.tczhong.com/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="https://www.tczhong.com/favicon.png">
    
    

</head>


    <body class=" ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="https://www.tczhong.com/">TC blog</a>
      </span>
      
        
        
        
        <div class="author-image">
          <img src="https://avatars2.githubusercontent.com/u/7358252?s=460&amp;v=4" alt="Author Image" class="img--circle img--headshot element--center">
        </div>
        
      
      
      <p class="site__description">
         I am who I am. Love Cloud and Data science 
      </p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">TC blog</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="https://www.tczhong.com/posts/">
						<span>Posts</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="https://www.tczhong.com/about/hello">
						<span>About</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="https://www.tczhong.com/tianchen_zhong.pdf">
						<span>My Resume</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="https://www.tczhong.com/posts/project/index.html">
						<span>Project</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <section class="social">
	
	
	
	<a href="https://github.com/cczhong11" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	<a href="https://linkedin.com/in/tianchen-zhong" rel="me"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	<a href="https://stackoverflow.com/users/7112540" rel="me"><i class="fab fa-stack-overflow fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	<a href="mailto:tczhong24@gmail.com" rel="me"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

      </div>
    </div>
    


  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>K Nearest Neighbor, K-Means and EM algorithm</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Dec 12, 2018
    
    
    
      
      
          in
          
          
              <a class="badge badge-category" href="https://www.tczhong.com/categories/ml">ML</a>
              
          
      
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 4 min read
</div>


  </header>
  
  
  <div class="post">
    <h1 id="k-nearest-neighbor-k-means-and-em-algorithm">K Nearest Neighbor, K-Means and EM algorithm</h1>
<p>These three algorithms are used for clustering. Let&rsquo;s talk about K Nearest Neighbor(KNN) first.</p>
<h2 id="k-nearest-neighbor">K Nearest Neighbor</h2>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/320px-KnnClassification.svg.png?1546962079122" alt=""></p>
<p>Example of k-NN classification. The test sample (green circle) should be classified either to the first class of blue squares or to the second class of red triangles. If k = 3 (solid line circle) it is assigned to the second class because there are 2 triangles and only 1 square inside the inner circle. If k = 5 (dashed line circle) it is assigned to the first class (3 squares vs. 2 triangles inside the outer circle).</p>
<p>In edger learning, it will choose a hypothesis space H, and it is the hard bias. Then given the training data, it can find a member of H, h, that best fits in it. Then h could be applied to any data.</p>
<p>The lazy learning is doing nothing in training step, just saving all data. In test step, it will make a prediction based on data in this step.</p>
<p>For K-nearest Neighbors, it finds K nearest neighbors in the training data. Then average the label or find the most labels to predict this data&rsquo;s label. If K=1, it always finds itself. There is no hard bias for KNN, and the soft bias is nearby point should have the same label.</p>
<p>The problem for KNN is: it is possible that different dimension will have different meaning, it is not wise just treat them as same. We could use $w _ i$ to deal with different dimension problem.$f(q) = \frac{\sum K(dist(x _ i,q))y _ i}{\sum K(dist(x _ i,q))}$</p>
<p>The kernel function is any positive semidefinite function of any two inputs. We could use the kernel to estimate small dataset and aggregate them to estimate the whole dataset. We can also use kernel smoothing.</p>
<h2 id="k-means">K-Means</h2>
<p>In the beginning, pre-define K centers in the observation.</p>
<p>It contains two steps, and the first one is to assign the center of the cluster. Assign each observation to the cluster whose mean has the least squared Euclidean distance. The second one is to update the new center which is the mean of the observations in the new cluster. Iterate many times, until the centers will not change.</p>
<p>The algorithm does not guarantee convergence to the global optimum. The result may depend on the initial clusters. As the algorithm is usually fast, it is common to run it multiple times with different starting conditions.</p>
<p>![](<a href="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/K-means">https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/K-means</a> _ convergence.gif/440px-K-means _ convergence.gif)</p>
<h2 id="em-algorithm">EM algorithm</h2>
<p>The EM algorithm is a general idea to calculate the unknown parameters. Let&rsquo;s use Gaussian Mixture Models as an example to talk about this model.</p>
<p>If there are many gaussian models mixing, we could get sampled data from this model. How could we estimate the $\mu _ i$ for these value?</p>
<p>Follow the MLE idea, we could get likelihood function with $\prod _ {i} e^{-\frac{(x _ {i}-\mu _ {j})^{2}}{2\sigma^{2}}}$ with $\mu _ j$. If we consider the prior $\lambda _ j$ for model j. The most possible for $\mu$ is
$$\boldsymbol{\mu} _ {ML}=\arg\max _ {\mu _ {1},\mu _ {2}}\prod _ {i}\sum _ {j}\lambda _ {j}e^{-\frac{(x _ {i}-\mu _ {j})^{2}}{2\sigma^{2}}}$$. But there is no analytical solution for this function, EM algorithm could give a local maximum, not necessary to be global maximum.</p>
<p>If we could get a table Z, when $x _ i$ from Gaussian j,$Z _ {i,j}=1$,otherwise 0. The $\hat \mu _ j = \sum _ i Z _ {i,j}X _ i / \sum Z _ {i,j}$. If we don&rsquo;t know it, we could estimate it with $\hat \mu _ j = \sum E[Z _ {i,j}|\bar \mu] X _ i / \sum E[Z _ {i,j}|\bar \mu]$.</p>
<p>The basic idea for EM is:</p>
<ol>
<li>Assume the $\mu _ j$ in the model</li>
<li>Classify data point to each model</li>
<li>Re-estimate the $\mu _ j$</li>
<li>Repeat</li>
</ol>
<p>In GMM:</p>
<ol>
<li>E steps: $$E \left[z _ {i,j}|\mu^{[k]}\right]=\frac{\lambda _ {j}L\left(x _ {i}|\mu=\mu _ {j}^{[k]}\right)}{\sum _ {j^{\prime}}\lambda _ {j^{\prime}}L\left(x _ {i}|\mu=\mu _ {j^{\prime}}^{[k]}\right)}$$
In this step, it could classify data point to each cluster.</li>
<li>M step: $$\mu _ {j}^{[k+1]}=\frac{\sum _ {i}E\left[z _ {i,j}|\mu^{[k]}\right]\cdot x _ {i}}{\sum _ {i}E\left[z _ {i,j}|\mu^{[k]}\right]}$$ In this step, it could re-estimate the $\mu _ j$</li>
</ol>
<p>if L is bounded, then it can converge to a (not necessarily global) local minimum.</p>
<p>We could see the KMeans algorithm has the similar idea with EM algorithm.</p>

  </div>
  

<div class="navigation navigation-single">
    
    <a href="https://www.tczhong.com/posts/cc/iot/" class="navigation-prev">
      <i aria-hidden="true" class="fa fa-chevron-left"></i>
      <span class="navigation-tittle">Virtual IoT Device on Cloud</span>
    </a>
    
    
    <a href="https://www.tczhong.com/posts/ml/decisiontree/" class="navigation-next">
      <span class="navigation-tittle">Decision tree basic concepts</span>
      <i aria-hidden="true" class="fa fa-chevron-right"></i>
    </a>
    
</div>


  

  
    
        <div id="disqus_thread"></div>
<script type="text/javascript">
    

    (function () {
    if (location.hostname === "localhost" ||
      location.hostname === "127.0.0.1" ||
      location.hostname === "") {
      return;
    }
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    var disqus_shortname = 'tczhong';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || 
      document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

<noscript>
  Please enable JavaScript to view the
  <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by
  <span class="logo-disqus">Disqus</span>
</a>

    


</article>


        </div>
        
    

<script defer src="https://use.fontawesome.com/releases/v5.11.2/js/all.js" integrity="sha384-b3ua1l97aVGAPEIe48b4TC60WUQbQaGi2jqAWM90y0OZXZeyaTCWtBTKtjW2GXG1" crossorigin="anonymous"></script>


    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
        
    <script type="text/javascript">
        
        hljs.initHighlightingOnLoad();
    </script>
    



    



    </body>
</html>
