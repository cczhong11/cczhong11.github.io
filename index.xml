<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TC blog</title>
    <link>http://www.tczhong.com/</link>
    <description>Recent content on TC blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 27 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://www.tczhong.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Slack and Piazza</title>
      <link>http://www.tczhong.com/posts/cc/piazza/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/piazza/</guid>
      <description>Piazza and Slack integration Slack is very popular in the workspace. As a TA in Cloud Computing Course (15-619), we also use Slack to discuss with each other and solve student&amp;rsquo;s problem together. Piazza is another common tool we used every day. It is like a forum within the course.
When a student asks a question, we want to answer them quickly. Piazza could send you new questions in real time with email.</description>
    </item>
    
    <item>
      <title>Machine learning basic concepts</title>
      <link>http://www.tczhong.com/posts/ml/machinelearningreview/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/ml/machinelearningreview/</guid>
      <description>Deep Neural Networks Neural Networks In general, neural networks have lots of node and each node will perform a transformation. In the easiest way, a linear transmission could be viewed as $\sum w_i x_i$. It is the hard bias for this neural network, it is how each neuron could do. Neural Networks are also built as a layered Feedforward network, and the hard bias is the topology and activation function, they represent the expressive power for the network.</description>
    </item>
    
    <item>
      <title>Read Static file in Apache Samza</title>
      <link>http://www.tczhong.com/posts/cc/samzastaticfile/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/samzastaticfile/</guid>
      <description>Scenario Apache Samza is a stream processing framework developed by Linkedin. It allows we to build stateful applications that process data in real-time and it could read data from Apache Kafka smoothly. It has handful of examples on how to read stream data from Kafka topic. However, it did not include any working examples for Apache Samza to consume static data and stream data at the same time in stream processing.</description>
    </item>
    
    <item>
      <title>Virtual IoT Device on Cloud</title>
      <link>http://www.tczhong.com/posts/cc/iot/</link>
      <pubDate>Tue, 27 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/iot/</guid>
      <description>Virtual IoT Device on Cloud IoT is very hot in these days. I believe in the future, all the devices in the home will have some connections with the internet. We could easily get the stream data from these devices and do some analysis to find the trend or abnormal event. Thanks for 5G and IPV6, it is possible to have enough addresses and high speed network.
There are some key skills that are required in the companies.</description>
    </item>
    
    <item>
      <title>Alexa music player project</title>
      <link>http://www.tczhong.com/posts/project/alexamusic/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/project/alexamusic/</guid>
      <description>Alexa music player Amazon Alexa is a good voice assistant in our home. As a speaker, the best usage is still a
//debug when just see error in cloudwatch, see your alexa app, some error message display on the screen</description>
    </item>
    
    <item>
      <title>How to build your own apple script for omnifocus</title>
      <link>http://www.tczhong.com/posts/mac/omnifocusapplescriptbasic/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/mac/omnifocusapplescriptbasic/</guid>
      <description>How to use apple script with Omnifocus Omnifocus is a very great to-do list app in Mac and iPhone. It is expensive and very good to use. We could also use apple script to make it become more powerful.
List all done tasks In many cases, we need to do summary on how many tasks we have done that day or week. Therefore, we could just log out all completed tasks and send to notebook/Day one.</description>
    </item>
    
    <item>
      <title>Intern Project</title>
      <link>http://www.tczhong.com/posts/project/intern/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/project/intern/</guid>
      <description>Intern Project In this summer, I am the intern from the Cloud infrastructure team in Walmart Sam&amp;rsquo;s Club and my manager is Ciby. My project is to design a scheduler to help developers to dynamically scale CosmosDB resource based on time.
Background and Problem I want to talk about some background information about my project. Azure Cosmos DB is a popular database among all application development teams in Sams. The billing of usage is based on Resource Unit configuration.</description>
    </item>
    
    <item>
      <title>HackMidwest -- Sonder</title>
      <link>http://www.tczhong.com/posts/project/hackmidwest/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/project/hackmidwest/</guid>
      <description>Hack Midwest &amp;ndash; Team Sonder We won Sprint Prize and Cloudinary Prize.
Sonder is a proximity-based multi-purpose private network with applications in home automation, event planning and anonymous communication, enabled through text-based (SMS) virtual assistant. It allows user to anonymously interact with authorized peers.
The problem is every virtual automation assistance needs wifi to communicate with each other, we want to make a AP-less virtual automation. The main idea is to use cellular services to interact with a central hub to process information in areas such as home/office, social gatherings and hackathons.</description>
    </item>
    
    <item>
      <title>Project List</title>
      <link>http://www.tczhong.com/posts/project/</link>
      <pubDate>Mon, 23 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/project/</guid>
      <description> 2018  Hackmidwest: NodeJs, DynamoDB, Twillio, Alexa, Foursquare, Codeception Hackathon: Java, Ionoic, Google Map, Azure CosmosDB, Blob, Photo Mobi2mp3: Python, tts Lucene Based search engine: Java, BM25, learning to rank, Course project Twitter Analytics Web Service:Java, Hadoop, MySQL, Spark, JMeter, AWS, Course project resume generated tool: Python, latex, JSON Social Networking Timeline with Heterogeneous Back-ends:Java, MongoDB, Course project Input Text Predictor:Java, Redis, Course project Streaming Data Processing System:Rider-Driver Matching:Kafka, Course project  2017  Introduction to Computer system: C, web proxy, shell, Cache, malloc, Course Project Real-time Embedded System Kernel: multi-thread real-time kernel, Loadable Kernel Modules, embedded Linux, C, Assembly University Chatbot: C#, Python, SQL server, Azure 2048 AI Solver: Python, Keras, Tensorflow  2016  Academic entities relationship finding service: Java, Restful Android application to detect and train attention based on EEG signal: Java, Andriod, Mindwave  </description>
    </item>
    
    <item>
      <title>Solve TimeZone in Azure Web App</title>
      <link>http://www.tczhong.com/posts/cc/azure-timezone/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/azure-timezone/</guid>
      <description>TimeZone&amp;rsquo;s Problem In my intern project, I need to handle timezone problem. Because in US, there is Daylight time saving and 5 diffferent timezone. My code should provide service for people in different timezones. Therefore, in the front end, I could allow user input time in their own timezone, but I should save date and time in GMT+0. Then I could make sure all time in database is saved in the same timezone.</description>
    </item>
    
    <item>
      <title>Leetcode Answer websites</title>
      <link>http://www.tczhong.com/posts/project/leetcodeanswer/</link>
      <pubDate>Sun, 08 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/project/leetcodeanswer/</guid>
      <description>The idea It is popular for students to practise their coding skills on leetcode.com. It offers very good questions and good articles. However, it is not easy for people to learn from other good answers. Although it provides discussion, but people needs to go through threads by threads to find the right answers. I want to build a website for myself to find questions easily.
All codes are belong to Leetcode.</description>
    </item>
    
    <item>
      <title>Solve NoSuchMethodError in Azure JAVA SDK </title>
      <link>http://www.tczhong.com/posts/cc/azure-error/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/azure-error/</guid>
      <description>Problem I met a NoSuchMethodError in Azure Java SDK. The error message is like the following:
Exception in thread &amp;quot;main&amp;quot; java.lang.NoSuchMethodError: com.microsoft.azure.credentials.ApplicationTokenCredentials.proxy()Ljava/net/Proxy;  It was very strange and I searched on the stackoverflow. And it shows the problem could be confliction in package version. Therefore I looked into the code to find the reason.
Solution In the beginning, I needed to go into the source code to see what happened there.</description>
    </item>
    
    <item>
      <title>Create a thumbnail of photo using Java</title>
      <link>http://www.tczhong.com/posts/java/createthumbnail/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/java/createthumbnail/</guid>
      <description>Create a thumbnail of photo using Java Why we need a thumbnail In the mobile application, if we want to show a picture quickly and we do not care the clarity of that image. We could create a thumbnail of that image, which is a smaller version of this image. The original image captured by iPhone X could be 10 MB, but the thumbnail only have 50 kb, which is much more handy to use when you need to show them quickly.</description>
    </item>
    
    <item>
      <title>Spring MVC model</title>
      <link>http://www.tczhong.com/posts/java/spring_mvc/</link>
      <pubDate>Thu, 21 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/java/spring_mvc/</guid>
      <description>Spring boot Framework Spring boot framework is a strong framework helps you build a MVC model web service quickly. So in the first place, we need to understand what is MVC model
Model-View-Controller  Model  Model represent knowledge. It represents how basic items interact with each other.
 Views  A view is a (visual) representation of its model. A view is attached to its model (or model part) and gets the data necessary for the presentation from the model by asking questions.</description>
    </item>
    
    <item>
      <title>How to draw graph in code</title>
      <link>http://www.tczhong.com/posts/mac/graphvis/</link>
      <pubDate>Thu, 24 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/mac/graphvis/</guid>
      <description>Basic Drawing We could use Graphviz to draw a graph in code and it is also easily to used in Markdown file. In this blog, I will focus on dot tool.
In the beginning, we need to install it. If you are a Mac user, we could use brew install graphvis. For other user, you could download file from the official website.
You could create a file with the following code.</description>
    </item>
    
    <item>
      <title>Anomaly and Mixture of Gaussian and </title>
      <link>http://www.tczhong.com/machinelearning/anomaly-and-multivariate-gaussia-distribution/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/anomaly-and-multivariate-gaussia-distribution/</guid>
      <description>What is Anomaly In supervised view, we could think these points are with some labels. In unsupervised view, there are outliers, which means they have very low probability.
When we could model a dataset with a distribution, we could find which point&amp;rsquo;s probability is very low, then we could think them as a outlier.
Multivariate Gaussian distribution $$P(x) = \frac{1}{\Sigma \sqrt {2\pi}} e^{-({x - \mu } )^2/{2\Sigma ^2}}$$
In this distribution, we could prove $E[X] = \mu$, $Cov[X]=\Sigma$</description>
    </item>
    
    <item>
      <title>Decision Tree</title>
      <link>http://www.tczhong.com/machinelearning/decision-tree/</link>
      <pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/decision-tree/</guid>
      <description>what is desicion tree Decision tree is tree-based algorithm and it has two type: regression tree and classification tree.
The main idea for decision tree is to choose one place to cut the whole sample space at one time to get two branches and cut recurisively. In ID3 algorithm, we only consider one demension to cut the space. You can think of the hypothesis function of decision trees as partitioning the input space with axis-aligned boundaries.</description>
    </item>
    
    <item>
      <title> Dimension Rerduction</title>
      <link>http://www.tczhong.com/machinelearning/dimension_reduction/</link>
      <pubDate>Sat, 05 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/dimension_reduction/</guid>
      <description>Dimension Rerduction PCA Principal component analysis (PCA) looks at “simplifying” the data in another manner, by preserving the axes of major variation in the data.
Hypothesis function $h_\theta (x) = UWx, \theta={U \in R^{n*k},W\in R^{k*n}}$. We are compressing input by multiplying by a low rank matriex.
Loss function $$\ell(h_\theta(x), x)=|\mu - x|_2^2$$
Optimization problem. $$minimize{U,W} = \sum{I=1}^m | UWx^{(i)}-x^{(i)}|^2_2$$
procedure Given: normalized data matrix X, k components
 Compute singular value decomposition $USV^T = X$, where $U,V$ is orthogonal and $S$ is diagonal matrix of singular values.</description>
    </item>
    
    <item>
      <title>How to mount NTFS in Mac</title>
      <link>http://www.tczhong.com/posts/mac/ntfs/</link>
      <pubDate>Sat, 05 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/mac/ntfs/</guid>
      <description>Install FUSE FUSE for macOS allows you to extend macOS&amp;rsquo;s native file handling capabilities via third-party file systems. You could install it here.
Install ntfs-3g Use
brew install ntfs-3g  If you run into error, Error: Could not symlink sbin/mkntfs. You need to use the absolute path to run the following function.
Next, we need to umount our driver, since it only has read permission. And create an endpoint for it.</description>
    </item>
    
    <item>
      <title>Clustering</title>
      <link>http://www.tczhong.com/machinelearning/cluster/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/cluster/</guid>
      <description>unsupervised learning the general philosophy of unsupervised learning is that we want to discover some kind of structure in the data. Different unsupervised learning methods work in very different ways, and discover very different kinds of structure, but they all have this similar element.
Recall from our presentations on supervised learnign that the three aspects of a supervised learning algorithm are: 1. a hypothesis function;($R^n -&amp;gt; R^n$). Mapping input back to this input space.</description>
    </item>
    
    <item>
      <title>Cross-validation</title>
      <link>http://www.tczhong.com/machinelearning/validation/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/validation/</guid>
      <description>Cross-validation Hold - out validation In this method, we will have 70% training data and 30% validation data. When we do the training, we will only use the training data, then we will use the validation data to test our model and tuning the hyperparameters
 parameters:$\theta$ hypermeters: degree of polynominal, amount of regulazation&amp;hellip;  K-hold validation In this method, we will divide the data into k part, then we will use k-1 data to train the model and have the rest one validate the model.</description>
    </item>
    
    <item>
      <title>Hypothesis testing</title>
      <link>http://www.tczhong.com/machinelearning/hypothesis-testing/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/hypothesis-testing/</guid>
      <description>Hypothesis testing sample statistics and central limit theorem When we have a dataset, we could sample data from this set. And we could use sample result to estimate statistics for total set. For example, in total we have 10000 data points, but we could not get them all. Therefore, we sampled 100 data points to guess the original dataset expectation and variance. We also could know the sample mean&amp;rsquo;s expectation and variance.</description>
    </item>
    
    <item>
      <title>Logistic regression</title>
      <link>http://www.tczhong.com/machinelearning/logistic-regression/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/logistic-regression/</guid>
      <description>Logistic regression This method is a varanice of a linear classier. The key this is we want to use $sigmod(\theta X)$ to classifer value.
Gradient descent This method like linear regression, it needs Least square minimization for error. Because there is only 0 and 1. Therefore we could use probability to identify the error. $g(z) = \frac{1}{1+e^{-z}}$
$P(y=0|x,\theta) = sigmod(\theta X)$
$P(y=1|x,\theta) = 1-sigmod(\theta X)$
这里使用最大似然估计，目的是得到在已知样本的情况下最有可能的$\theta$ 的值。
$L(\theta) = \prod p(y^i|x^i;\theta)$</description>
    </item>
    
    <item>
      <title>Maximum likelihood estimation</title>
      <link>http://www.tczhong.com/machinelearning/maximum-likelihood-estimation/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/maximum-likelihood-estimation/</guid>
      <description>Maximum likelihood estimation In the beginning, we could get a sample set $x_1,x_2,&amp;hellip;$, and we assume these points are independent with each other. Then we could get the possibility for us to get these points. $p(x_1,x_2,x_3&amp;hellip;,xm;\theta) = \prod{i=1}^m p(x_i;\theta)$
So, what&amp;rsquo;s the most possible $\theta$ under this circumstance, it is when this possibility get its maximum value. Therefore, we want to maximize $\theta$, to calculate $$maximize\theta \; \prod{i=1}^m p(x^{(i)};\theta)$$ If we take the log to $p(x)$, we could get the log likelihood of the data, which is also equivalent to that value.</description>
    </item>
    
    <item>
      <title>Neural network</title>
      <link>http://www.tczhong.com/machinelearning/neuralnetwork/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/neuralnetwork/</guid>
      <description>Neural network The key difference is it combines non-linear function with linear function. It could implement any function by using enough neural.
Before, we could learn $h_\theta(x)=\theta^T\phi(x)$, if we still set $\phi(x)$ to be a linear function, which we think it should be a two-stage function, but in the end it is still a one stage linear function.
Hypothesis function Neural networks are a simple extension of this idea, where we additionally apply a non-linear function after each linear transformation.</description>
    </item>
    
    <item>
      <title>Probability</title>
      <link>http://www.tczhong.com/machinelearning/probaility/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/probaility/</guid>
      <description>Probability Here we want to talk about some basic knowledges of probability. In the beginning, we need to understand some notations in probability and they are confused in some times.
$p(x),p_x$ here, $x$ is an exact number and we could have an exact number for this value from 0 to 1. For exmaple, $p(1)=0.5,p(0)=0.5$
$p(X)$ here, $X$ is a random variable, it represents all the possible value. We could use $p(X=1)$ to represent the exact value.</description>
    </item>
    
    <item>
      <title>Probability modeling</title>
      <link>http://www.tczhong.com/machinelearning/probability_modeling/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/probability_modeling/</guid>
      <description>Probability modeling What is probability modeling? It is a high dimension distribution for p(X). It represents distribution more compactly by exploiting conditional independencies.
Bayesian Network The main idea is to represent $P(X)$ with $\prod P(X_i|parents(X_i))$. It is also a generative model, which means it construct distribution as a &amp;lsquo;sequential story&amp;rsquo;.
Markov chain Monte Carlo Markov chain Monte Carlo (MCMC) refers to a class of methods that approximately draw samples from over the hidden variables</description>
    </item>
    
    <item>
      <title>Recommendation</title>
      <link>http://www.tczhong.com/machinelearning/recommender/</link>
      <pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/machinelearning/recommender/</guid>
      <description>Recommendation Collaborative filtering Solely upon the preferences that other users have indicated for these items.(rating for items): row -&amp;gt; users column-&amp;gt; items
The task of collaborative filtering, then, is to “fill in” the remaining entries of this matrix given the observed matrix. This X matrix that we observed is sparse but the unknown entries do not correspond to actual zeros in the matrix, but are rather just truly unknown.</description>
    </item>
    
    <item>
      <title>Undertow configuration</title>
      <link>http://www.tczhong.com/posts/cc/undertow/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/undertow/</guid>
      <description>Undertow This is a very fast Java web server. When using this web server, I met some problems but I could not find enough answers even on the stackOverflow. Therefore, I decided to write my experience down.
How to set parameters to each Servlet? It is necessary for us to pass some parameters to Serlet functions. One way to do this is to use addInitParam when adding Servlet. Like the following code.</description>
    </item>
    
    <item>
      <title>Scala join RDD tips</title>
      <link>http://www.tczhong.com/posts/cc/scala-spark-join/</link>
      <pubDate>Sat, 21 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/scala-spark-join/</guid>
      <description>Why Spark RDD join is expensive As we know, Join is the most expensive operation on rdd. The reason is when we join two rdd, it requires corresponding keys from each RDD are located at the same partition so that they can be combined locally. Therefore, we will shuffle keys from each rdd to make sure they are in the same partition.
You could learn more about rdd join from here</description>
    </item>
    
    <item>
      <title>Improve performance on HBase</title>
      <link>http://www.tczhong.com/posts/cc/hbase-reading/</link>
      <pubDate>Tue, 17 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/hbase-reading/</guid>
      <description>Tips on improving reading performance In some scenario, we need to have high RPS in HBase reading.Therefore, we could change some configuration in HBase to meet this requirement. I found this blog very helpful. HBase official guide is also great.
 Increase hfile.block.cache.size and decrease hbase.regionserver.global.memstore.size. The first configuration is for reading cache and the second one is writing cache. The sum of two value should be 0.8 Decrease BLOCKSIZE in HBase table.</description>
    </item>
    
    <item>
      <title>Mapreduce custom output</title>
      <link>http://www.tczhong.com/posts/cc/mapreduce/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/mapreduce/</guid>
      <description>Introduction Mapreduce is a very strong computing framework and we could use it to transform data to HDFS. Acutally, we could use Mapreduce to write data to any databse.
Basic input and output The key thing in Mapreduce is Mapper and Reducer. We use the following code snippets to build a mapper. Here, Mapper&amp;lt;Object, Text, Text, Text&amp;gt; means input key and value class and ouput key and value class. Please notice that we could not use string and int here, since it is not fit the requirement in HDFS.</description>
    </item>
    
    <item>
      <title>GCP for Spark</title>
      <link>http://www.tczhong.com/posts/cc/gcp-spark/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/gcp-spark/</guid>
      <description>GCP is very cheap compared with AWS and Azure. However, it did not have enough documentation and I met some problems that did not even on StackOverflow. That&amp;rsquo;s why I want to write this blog.
Start your cluster We could use command line with GCP CLI to start cluster.
gcloud dataproc clusters create cluster-name --project=project-id --bucket outputbucket --initialization-actions gs://xxx/jupyter.sh --master-machine-type=n1-standard-2 --worker-machine-type=n1-standard-1 --zone=xxxx  Install external Python package on Spark If we want to use your own package and Juypter NoteBook on Spark, you need to contain an initialization step for your cluster.</description>
    </item>
    
    <item>
      <title>My first blog</title>
      <link>http://www.tczhong.com/about/hello/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/about/hello/</guid>
      <description>Hello World This is my first blog and I want to express something I learned in my graduate year. CMU is a very great place and I could meet many clever and hard-working students in this place. I learn the latest technology and skills in this school, and I also gain many precious experiences here.
Spend time wisely I believe I have a good time management skill and I could handle 4 courses in CMU in one semester.</description>
    </item>
    
    <item>
      <title>Spark for ETL</title>
      <link>http://www.tczhong.com/posts/cc/spark-etl/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/cc/spark-etl/</guid>
      <description>There is not much information about how could we perform complex operation on pySpark. I summary some tips from stackoverflow and my experience. Hope it will be helpful for you.
How to Read JSON to DataFrame There are serveral ways to read json in Spark. The most common way is to load json in a DataFrame. Why not rdd? Because json contains some hierachy information and it could not represent well in RDD.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.tczhong.com/posts/ml/knn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/ml/knn/</guid>
      <description>K Nearest Neighbor, K-Means and EM algorithm These three algorithms are used for clustering. Let&amp;rsquo;s talk about K Nearest Neighbor(KNN) first.
K Nearest Neighbor Example of k-NN classification. The test sample (green circle) should be classified either to the first class of blue squares or to the second class of red triangles. If k = 3 (solid line circle) it is assigned to the second class because there are 2 triangles and only 1 square inside the inner circle.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.tczhong.com/posts/ml/decisiontree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/ml/decisiontree/</guid>
      <description>Decision tree Decision tree is an essential algorithm in Machine Learning field. Using Decision tree can express all possible functions among the data. Understanding the decision tree requires us to know entropy in the first place.
Entropy Consider we flip an unbiased coin, and we can get head and tail both in 50% chance. However, if we flip a biased coin, we can get head in 90% chance and tail 10% chance.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://www.tczhong.com/posts/ml/mle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://www.tczhong.com/posts/ml/mle/</guid>
      <description>Maximum Likelihood Estimation This is a fundamental algorithm, but I still want to write a blog about it. Let&amp;rsquo;s start with the basic idea.
Probability If we have a situation $S_1$ and event A may happen. For example, under the same situation, the event A happens 7 out of 10. We could see the frequency of event A is 0.7. Under much experiment with the same situation, if we still get the same result, we could see the probability of event A in this situation is 0.</description>
    </item>
    
  </channel>
</rss>