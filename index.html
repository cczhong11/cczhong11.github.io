<!DOCTYPE html>
<html lang="en" class="wf-firasans-n4-active wf-active">
	<head>
    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <!-- Enable responsiveness on mobile devices --> 
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    
    	
    <meta name="generator" content="Hugo 0.37" />
    <title></title>
    <meta content="" property="og:title">
    <meta content="" property="og:description">    
    <!-- CSS --> 
    <link rel="stylesheet" href="https://cczhong11.github.io/css/print.css" media="print">
    <link rel="stylesheet" href="https://cczhong11.github.io/css/poole.css">
    <link rel="stylesheet" href="https://cczhong11.github.io/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Sans:300,300i,400,400i,500">
    
    <script defer src="https://use.fontawesome.com/releases/v5.0.6/js/all.js"></script>
    <!-- highlight.js--> 
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/vs.min.css">
    <!-- Customised CSS -->
    <link rel="stylesheet" href="https://cczhong11.github.io/css/custom.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://cczhong11.github.io/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="https://cczhong11.github.io/favicon.png">
    <!-- RSS --> 
    <link href="https://cczhong11.github.io/index.xml" rel="alternate" type="application/rss+xml" title="" />
    <link href="https://cczhong11.github.io/index.xml" rel="feed" type="application/rss+xml" title="" />

	</head>
    <body>
        <div class="sidebar">
	<div class="container text-center sidebar-sticky">
		<div class="sidebar-about text-center">
			<a href="https://cczhong11.github.io/"><h1 class="brand"></h1></a>
			 <img src="https://cczhong11.github.io/img/kirby.png" alt="Author Image" class="img-circle headshot center"> 
			<p class="lead">
				 I am who I am. Love Cloud and Data science 
			</p>
		</div>
		
<div>
	<ul class="sidebar-nav">
		
		
				<li>
					<a href="https://cczhong11.github.io/posts/"> <span>Posts</span></a>
				</li>
				<li>
					<a href="https://cczhong11.github.io/about/"> <span>About</span></a>
				</li>
		</li>
	</ul>
</div>

        <p>
		<section class="row text-center">
	
	
	
	&nbsp;<a href="https://github.com/cczhong11"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	&nbsp;<a href="https://linkedin.com/in/tianchen-zhong"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	&nbsp;<a href="mailto:tczhong24@gmail.com"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
</section>

        </p>
		<p class="copyright">&copy; 2018 Tc Zhong.
        <a href="https://creativecommons.org/licenses/by/4.0">Some Rights Reserved</a>.<br/>Built with <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/htr3n/hyde-hyde">hyde-hyde</a>.
        </p>
	</div>
	<div>
	</div>
</div>

        <div class="content container">
            <div class="posts">
    
    <div class="post">
        <h1 class="post-title">
            <a href="https://cczhong11.github.io/posts/cc/scala-spark-join/">Scala join RDD tips</a>
        </h1>
        <span class="post-date">Sat, Apr 21, 2018</span>
        Why Spark RDD join is expensive As we know, Join is the most expensive operation on rdd. The reason is when we join two rdd, it requires corresponding keys from each RDD are located at the same partition so that they can be combined locally. Therefore, we will shuffle keys from each rdd to make sure they are in the same partition.
You could learn more about rdd join from here 
        <div class="read-more-link">
            <a href="https://cczhong11.github.io/posts/cc/scala-spark-join/">Read More…</a>
        </div>
        
    </div>
    <div class="post">
        <h1 class="post-title">
            <a href="https://cczhong11.github.io/posts/cc/hbase-reading/">Improve performance on HBase</a>
        </h1>
        <span class="post-date">Tue, Apr 17, 2018</span>
        Tips on improving reading performance In some scenario, we need to have high RPS in HBase reading.Therefore, we could change some configuration in HBase to meet this requirement. I found this blog very helpful. HBase official guide is also great.
 Increase hfile.block.cache.size and decrease hbase.regionserver.global.memstore.size. The first configuration is for reading cache and the second one is writing cache. The sum of two value should be 0.8 Decrease BLOCKSIZE in HBase table. 
        <div class="read-more-link">
            <a href="https://cczhong11.github.io/posts/cc/hbase-reading/">Read More…</a>
        </div>
        
    </div>
    <div class="post">
        <h1 class="post-title">
            <a href="https://cczhong11.github.io/posts/cc/mapreduce/">Mapreduce custom output</a>
        </h1>
        <span class="post-date">Tue, Apr 10, 2018</span>
        Introduction Mapreduce is a very strong computing framework and we could use it to transform data to HDFS. Acutally, we could use Mapreduce to write data to any databse.
Basic input and output The key thing in Mapreduce is Mapper and Reducer. We use the following code snippets to build a mapper. Here, Mapper&lt;Object, Text, Text, Text&gt; means input key and value class and ouput key and value class. Please notice that we could not use string and int here, since it is not fit the requirement in HDFS. 
        <div class="read-more-link">
            <a href="https://cczhong11.github.io/posts/cc/mapreduce/">Read More…</a>
        </div>
        
    </div>
    <div class="post">
        <h1 class="post-title">
            <a href="https://cczhong11.github.io/posts/cc/gcp-spark/">GCP for Spark</a>
        </h1>
        <span class="post-date">Tue, Mar 27, 2018</span>
        GCP is very cheap compared with AWS and Azure. However, it did not have enough documentation and I met some problems that did not even on StackOverflow. That&rsquo;s why I want to write this blog.
Start your cluster We could use command line with GCP CLI to start cluster.
gcloud dataproc clusters create cluster-name --project=project-id --bucket outputbucket --initialization-actions gs://xxx/jupyter.sh --master-machine-type=n1-standard-2 --worker-machine-type=n1-standard-1 --zone=xxxx  Install external Python package on Spark If we want to use your own package and Juypter NoteBook on Spark, you need to contain an initialization step for your cluster. 
        <div class="read-more-link">
            <a href="https://cczhong11.github.io/posts/cc/gcp-spark/">Read More…</a>
        </div>
        
    </div>
    <div class="post">
        <h1 class="post-title">
            <a href="https://cczhong11.github.io/posts/cc/spark-etl/">Spark for ETL</a>
        </h1>
        <span class="post-date">Tue, Mar 27, 2018</span>
        There is not much information about how could we perform complex operation on pySpark. I summary some tips from stackoverflow and my experience. Hope it will be helpful for you.
How to Read JSON to DataFrame There are serveral ways to read json in Spark. The most common way is to load json in a DataFrame. Why not rdd? Because json contains some hierachy information and it could not represent well in RDD. 
        <div class="read-more-link">
            <a href="https://cczhong11.github.io/posts/cc/spark-etl/">Read More…</a>
        </div>
        
    </div>
</div>
            <div class="footer">
                
            </div>
        </div>
        
                
    </body>
</html>
